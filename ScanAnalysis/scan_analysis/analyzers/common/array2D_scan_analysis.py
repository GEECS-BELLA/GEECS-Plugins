"""
Array2DScanAnalyzer

General analyzer for 2D array type data.
Child to ScanAnalysis (./scan_analysis/base.py)

This provides a general framework for using an ImageAnalyzer to do analysis and post processing
over a scan.

It will generate some default type of visual representation of the data. For a 'noscan' it will
create an average image and a .gif. For a parameter scan, it will create an image array with each
individual image averaged over the bin # (e.g. scan parameter).

It can make use of multi threaded or multi processing of the images. The method applied is determined
by the attribute self.run_analyze_image_asynchronously in the ImageAnalyzer class. A setting of False
will use parallel processes and True will run multi threaded.

The method used for executing the ImageAnalysis.analyze_image method is _process_all_shots_parallel.
It is expected that the ImageAnalysis.analyze_image method will return a dict generated by the 'build_return_dict'
method of the base ImageAnalysis. This dict looks like this:
        return_dictionary = {
            "analyzer_input_parameters": input_parameters,
            "analyzer_return_dictionary": return_scalars,
            "processed_image": image of the type in the analyzer's return,
            "analyzer_return_lineouts": return_lineouts,
        }
The 'processed_image' item is the on that will be used to generate the visualized data.
The "analyzer_return_dictionary" contains a dict[str, float] that is used to write scalar
data to the 'sxxx.txt' file.
There is a rudimentary way to handle other types of return data using "analyzer_return_lineouts".
For example, a camera may be used as a spectrometer which is intended to generate a 1D array of
wavelength (energy) vs counts. Running this to through the default post_processing methods in
Array2DScanAnalysis is not appropriate. By default, Array2DScanAnalysis will ignore the lineout
data. But, child classes can be created to make use of the info by overwriting just a couple of
methods. An example is the HIMG_with_average_saving file. Creating a child class does still make
use of the other key parts of this framework (e.g. parallel processing, appending scalar data)

"""
# %% Imports
from __future__ import annotations

# --- Standard Library ---
import logging
import re
import traceback
from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor, as_completed
from pathlib import Path
from typing import TYPE_CHECKING, Union, Optional, List, TypedDict

# --- Third-Party Libraries ---
import numpy as np
import cv2
import matplotlib
import matplotlib.pyplot as plt
from matplotlib.colors import Normalize
import imageio as io
import h5py

# --- Local / Project Imports ---
from scan_analysis.base import ScanAnalysis
from image_analysis.base import ImageAnalyzer

# --- Type-Checking Imports ---
if TYPE_CHECKING:
    from geecs_data_utils import ScanTag
    from numpy.typing import NDArray
    from image_analysis.types import AnalyzerResultDict

# --- Global Config ---
use_interactive = False
if not use_interactive:
    matplotlib.use("Agg")

PRINT_TRACEBACK = True

# --- TypedDict Definitions ---
class BinImageEntry(TypedDict):
    value: float
    image: Optional[np.ndarray]
    scalar_results: Optional[dict[str,Union[float,int]]]


# below, some module level static functions that can't be members of the class so that the multi processing
# works as expected
def load_image_wrapper_static(shot_num: int, path: Path, analyzer_class: type) -> tuple[int, Optional[np.ndarray]]:
    """
    Module-level wrapper for multiprocessing-safe image loading.

    Args:
        shot_num (int): Shot number.
        path (Path): Path to image file.
        analyzer_class (type): A class (not instance) of ImageAnalyzer to instantiate in the subprocess.

    Returns:
        Tuple[int, Optional[np.ndarray]]: Shot number and loaded image.
    """
    try:
        analyzer = analyzer_class()
        image = analyzer.load_image(path)
        return shot_num, image
    except Exception as e:
        logging.warning(f"Failed to load image for shot {shot_num}: {e}")
        return shot_num, None

def analyze_preloaded_image_static(
    shot_num: int, image: np.ndarray, analyzer_class: type
) -> dict[str, Any]:
    try:
        analyzer = analyzer_class()
        result: AnalyzerResultDict = analyzer.analyze_image(image)
        return result
    except Exception as e:
        logging.error(f"Error analyzing image for shot {shot_num}: {e}")
        return {}

# %% classes
class Array2DScanAnalysis(ScanAnalysis):

    def __init__(self, scan_tag: ScanTag,
                 device_name: str,
                 image_analyzer: Optional[ImageAnalyzer] = None,
                 skip_plt_show: bool = True,
                 flag_logging: bool = True,
                 flag_save_images: bool = True):
        """
        Initialize the Array2DScanAnalysis class.

        Args:
            scan_tag (ScanTag): tag used to identify the scan directory containing data.
            device_name (str): Name of the device to construct the subdirectory path.
            skip_plt_show (bool): Flag that sets if matplotlib is tried to use for plotting
            flag_logging (bool): Flag that sets if error and warning messages are displayed
            flag_save_images (bool): Flag that sets if images are saved to disk
        """
        if not device_name:
            raise ValueError("Array2DScanAnalysis requires a device_name.")

        super().__init__(scan_tag, device_name=device_name,
                         skip_plt_show=skip_plt_show)

        self.image_analyzer = image_analyzer or ImageAnalyzer()

        # define flags
        self.flag_logging = flag_logging
        self.flag_save_images = flag_save_images

        self.file_tail: str = ".png"

        # organize various paths
        self.path_dict = {'data_img': Path(self.scan_directory) / f"{device_name}",
                          'save': (self.scan_directory.parents[1] / 'analysis' / self.scan_directory.name
                                   / f"{device_name}" / "Array2DScanAnalysis")
                          }

        self.data = {'shot_num': [], 'images': []}

        # Check if data directory exists and is not empty
        if not self.path_dict['data_img'].exists() or not any(self.path_dict['data_img'].iterdir()):
            if self.flag_logging:
                logging.warning(f"Data directory '{self.path_dict['data_img']}' does not exist or is empty. Skipping")

    def run_analysis(self, config_options: Optional[str] = None):
        if self.path_dict['data_img'] is None or self.auxiliary_data is None:
            if self.flag_logging:
                logging.info("Skipping analysis due to missing data or auxiliary file.")
            return

        if config_options is not None:
            raise NotImplementedError

        if self.flag_save_images and not self.path_dict['save'].exists():
            self.path_dict['save'].mkdir(parents=True)

        try:
            # Run the image analyzer on every shot in parallel.
            self._process_all_shots_parallel()

            # Depending on the scan type, perform additional processing.
            if len(self.data['images'])>2:
                if self.noscan:
                    self._postprocess_noscan()
                else:
                    if use_interactive:
                        self._postprocess_scan_interactive()
                    else:
                        self._postprocess_scan_parallel()

            self.auxiliary_data.to_csv(self.auxiliary_file_path, sep='\t', index=False)
            return self.display_contents

        except Exception as e:
            if PRINT_TRACEBACK:
                print(traceback.format_exc())
            if self.flag_logging:
                logging.warning(f"Warning: Image analysis failed due to: {e}")
            return

    def _process_all_shots_parallel(self):
        self._load_all_images_parallel()
        self._run_batch_analysis()
        self._run_image_analysis_parallel()

    def _build_image_file_map(self) -> None:
        """
        Build a mapping from shot number to image file path using a flexible filename regex.
        Only includes files whose suffix + format matches `file_tail` exactly.

        """
        self._image_file_map = {}

        image_filename_regex = re.compile(
            r"Scan(?P<scan_number>\d{3,})_"  # capture scan number
            r"(?P<device_subject>.*?)_"  # non-greedy device/subject
            r"(?P<shot_number>\d{3,})"  # capture shot number
            r"(?P<suffix>_[^.]*)?"  # optional suffix
            r"\.(?P<format>\w+)$"  # file format
        )

        for file in self.path_dict['data_img'].iterdir():
            if not file.is_file():
                continue

            m = image_filename_regex.match(file.name)
            if m:
                suffix = m.group('suffix') or ''
                file_format = m.group('format')
                tail = f"{suffix}.{file_format}"
                if tail != self.file_tail:
                    continue  # skip if it doesn't match the requested tail

                shot_num = int(m.group('shot_number'))
                if shot_num in self.auxiliary_data['Shotnumber'].values:
                    self._image_file_map[shot_num] = file
                    logging.info(f"Mapped file for shot {shot_num}: {file}")
            else:
                logging.debug(f"Filename {file.name} does not match expected pattern.")

        expected_shots = set(self.auxiliary_data['Shotnumber'].values)
        found_shots = set(self._image_file_map.keys())
        for m in sorted(expected_shots - found_shots):
            logging.warning(f"No file found for shot {m}")

    def _load_all_images_parallel(self) -> None:
        """
        Load all images in parallel (threaded or multi-processed) and store them in self.raw_images.

        This method identifies the correct image file path for each shot number using the defined
        file pattern, and loads the corresponding images using the ImageAnalyzer's `load_image` method.
        Threading or multiprocessing is used based on the value of `self.image_analyzer.run_analyze_image_asynchronously`.

        Results are stored in:
            - self._image_file_map: {shot_number: Path}
            - self.raw_images: {shot_number: np.ndarray}
        """
        self.raw_images = {}
        self._build_image_file_map()

        use_threads = self.image_analyzer.run_analyze_image_asynchronously
        Executor = ThreadPoolExecutor if use_threads else ProcessPoolExecutor

        analyzer_class = type(self.image_analyzer)

        with Executor() as executor:
            if use_threads:
                # Use instance method for threading
                futures = {
                    executor.submit(self.image_analyzer.load_image, path): shot_num
                    for shot_num, path in self._image_file_map.items()
                }
            else:
                # Use static method for multiprocessing
                futures = {
                    executor.submit(load_image_wrapper_static, shot_num, path, analyzer_class): shot_num
                    for shot_num, path in self._image_file_map.items()
                }

            for future in as_completed(futures):
                shot_num = futures[future]
                try:
                    if use_threads:
                        image = future.result()
                    else:
                        _, image = future.result()

                    if image is not None:
                        self.raw_images[shot_num] = image
                except Exception as e:
                    logging.error(f"Error loading image for shot {shot_num}: {e}")

    def _run_batch_analysis(self) -> None:
        """
        Perform optional batch-level analysis across all loaded images.
        This uses the analyze_image_batch() method of ImageAnalysis, which expects a list of images.
        An example use case: dynamically determine the background from a set of images
        and subtract it.

        Raises:
            RuntimeError: If no images have been loaded yet or if output length is invalid.
        """

        if not hasattr(self, 'raw_images') or not self.raw_images:
            raise RuntimeError("No images loaded. Run _load_all_images_parallel first.")

        try:
            # Extract keys and values from the dict
            shot_nums = list(self.raw_images.keys())
            image_list = list(self.raw_images.values())

            # Run batch analysis on the list of images
            processed_images = self.image_analyzer.analyze_image_batch(image_list)

            if processed_images is None:
                logging.warning("analyze_image_batch() returned None. Skipping.")
                self.raw_images = {}
                return

            if len(processed_images) != len(shot_nums):
                raise ValueError(f"analyze_image_batch() returned {len(processed_images)} images, "
                                 f"but {len(shot_nums)} were expected.")

            # Reconstruct raw_images using the original keys
            self.raw_images = dict(zip(shot_nums, processed_images))

        except Exception as e:
            logging.warning(f"Batch analysis skipped or failed: {e}")

    def _run_image_analysis_parallel(self) -> None:
        """
        Analyze each image in parallel (threaded or multi-processed).

        This method analyzes each image in `self.raw_images`, applying the `analyze_image()` method
        with the current analyzer config.

        The analyzer is applied using either threads (true) or processes (false) based on the `run_analyze_image_asynchronously` flag.
        Results (processed images and scalar analysis values) are stored in `self.data` and `self.auxiliary_data`.
        """
        logging.info('Starting the individual image analysis')
        self.data: dict[str, list] = {'shot_num': [], 'images': []}
        self.scalar_results: dict[str, list] = {'shot_num': [], 'scalar_results': []}


        Executor = ThreadPoolExecutor if self.image_analyzer.run_analyze_image_asynchronously else ProcessPoolExecutor
        logging.info(f'Using {"ThreadPoolExecutor" if Executor is ThreadPoolExecutor else "ProcessPoolExecutor"}')

        analyzer_class = type(self.image_analyzer)

        with Executor() as executor:
            if self.image_analyzer.run_analyze_image_asynchronously:
                futures = {
                    executor.submit(self.image_analyzer.analyze_image, img): sn # type: ignore[arg-type]
                    for sn, img in self.raw_images.items()
                }
            else:
                futures = {
                    executor.submit(analyze_preloaded_image_static, sn, self.raw_images[sn], analyzer_class): sn
                    for sn in self.raw_images
                }

            logging.info('Submitted image analysis tasks.')

            for future in as_completed(futures):
                shot_num = futures[future]
                try:
                    result: AnalyzerResultDict =  future.result()
                    image = result.get("processed_image")
                    scalars = result.get("analyzer_return_dictionary", {})

                    if image is not None:
                        self.data['shot_num'].append(shot_num)
                        self.data['images'].append(image)

                        self.scalar_results['shot_num'].append(shot_num)
                        self.scalar_results['scalar_results'].append(scalars)

                        logging.info(f"Shot {shot_num}: processed image stored.")
                        logging.info(f'analyzed shot {shot_num} and got {scalars}')

                    else:
                        logging.info(f"Shot {shot_num}: no image returned from analysis.")

                    for key, value in scalars.items():
                        if not isinstance(value, (int, float, np.number)):
                            logging.warning(
                                f"[{self.__class__.__name__} using {self.image_analyzer.__class__.__name__}] "
                                f"Analysis result for shot {shot_num} key '{key}' is not numeric (got {type(value).__name__}). Skipping."
                            )
                        else:
                            self.auxiliary_data.loc[self.auxiliary_data['Shotnumber'] == shot_num, key] = value

                except Exception as e:
                    logging.error(f"Analysis failed for shot {shot_num}: {e}")

    def _postprocess_noscan(self) -> None:
        """Perform post-processing for a no-scan: average images and create a GIF."""
        avg_image = self.average_images(self.data['images'])
        if self.flag_save_images:
            self.save_image_as_h5(avg_image, save_dir=self.path_dict['save'],
                                         save_name=f'{self.device_name}_average_processed.h5')
            save_name = f'{self.device_name}_average_processed_visual.png'
            self.save_normalized_image(avg_image, save_dir=self.path_dict['save'],
                                       save_name=save_name, label=save_name)
            display_content_path = Path(self.path_dict['save']) / save_name
            self.display_contents.append(str(display_content_path))
            # Create GIF
            filepath = self.path_dict['save'] / 'noscan.gif'
            self.create_gif(self.data['images'], filepath,
                            titles=[f"Shot {num}" for num in self.data['shot_num']])
            self.display_contents.append(str(filepath))

    def _save_bin_images(self, bin_key: int, processed_image: np.ndarray) -> None:
        """
        Helper method to save images for a single bin.
        This saves both the scaled and normalized images.
        """
        save_name_scaled = f"{self.device_name}_{bin_key}_processed.h5"
        save_name_normalized = f"{self.device_name}_{bin_key}_processed_visual.png"
        self.save_image_as_h5(processed_image,
                                     save_dir=self.path_dict["save"],
                                     save_name=save_name_scaled)
        self.save_normalized_image(processed_image,
                                   save_dir=self.path_dict["save"],
                                   save_name=save_name_normalized)
        if self.flag_logging:
            logging.info(f"Saved bin {bin_key} images: {save_name_scaled} and {save_name_normalized}")

    def _postprocess_scan_parallel(self) -> None:
        """
        Post-process a scanned variable by binning the images (from self.data) and then
        saving the resulting images in parallel.
        """
        # Use your existing parallel (or sequential) binning method to create binned_data.
        binned_data = self.bin_images_from_data(flag_save=False)

        # Save each bin's images concurrently using a thread pool.
        if self.flag_save_images:
            with ThreadPoolExecutor() as executor:
                futures = []
                for bin_key, bin_item in binned_data.items():
                    processed_image = bin_item["image"]
                    futures.append(executor.submit(self._save_bin_images, bin_key, processed_image))
                for future in as_completed(futures):
                    # Optionally handle exceptions:
                    try:
                        future.result()
                    except Exception as e:
                        logging.error(f"Error saving images for a bin: {e}")

        # Create an image grid if more than one bin exists.
        if len(binned_data) > 1 and self.flag_save_images:
            plot_scale = (getattr(self, "camera_analysis_settings", {}) or {}).get("Plot Scale", None)
            save_path = Path(self.path_dict["save"]) / f'{self.device_name}_averaged_image_grid.png'
            self.create_image_array(binned_data, plot_scale=plot_scale, save_path=save_path)
            self.display_contents.append(str(save_path))
        self.binned_data = binned_data

    def _postprocess_scan_interactive(self) -> None:
        """Perform post-processing for a scan: bin images and create an image grid."""
        # Bin images from the already processed data.
        binned_data = self.bin_images_from_data(flag_save=False)

        # Process each bin sequentially.
        for bin_key, bin_item in binned_data.items():
            processed_image = bin_item.get("image")
            if self.flag_save_images and processed_image is not None:
                self._save_bin_images(bin_key, processed_image)
            elif processed_image is None:
                logging.warning(f"Bin {bin_key} has no processed image; skipping saving for this bin.")

        # If more than one bin exists, create an image grid.
        if len(binned_data) > 1 and self.flag_save_images:
            plot_scale = (getattr(self, "camera_analysis_settings", {}) or {}).get("Plot Scale", None)
            save_path = Path(self.path_dict["save"]) / f"{self.device_name}_averaged_image_grid.png"
            self.create_image_array(binned_data, plot_scale=plot_scale, save_path=save_path)
            self.display_contents.append(str(save_path))

        self.binned_data = binned_data

    def bin_images_from_data(self, flag_save: Optional[bool] = None) -> dict[int, BinImageEntry]:
        """
        Groups the already processed images (stored in self.data) by their bin value
        (as defined in self.auxiliary_data) and averages the images for each bin.

        Args:
            flag_save (bool): Whether to save the binned images. Defaults to self.flag_save_images.

        Returns:
            dict: A dictionary mapping each bin value to a dict with keys 'value' (the bin parameter)
                  and 'image' (the averaged image).
        """
        if flag_save is None:
            flag_save = self.flag_save_images

        # Assume that self.auxiliary_data contains a column "Bin #" and that each shot number in self.data['shot_num']
        # corresponds to an entry in self.auxiliary_data. Also, assume self.scan_parameter holds the name of the parameter
        # used for binning.

        unique_bins = [int(b) for b in np.unique(self.auxiliary_data["Bin #"].values)]
        if self.flag_logging:
            logging.info(f"Unique bins from auxiliary data: {unique_bins}")

        binned_data: dict[int, BinImageEntry] = {}
        # Loop over each bin value
        for bin_val in unique_bins:
            # Get the shot numbers that belong to this bin.
            bin_shots = self.auxiliary_data[self.auxiliary_data["Bin #"] == bin_val]["Shotnumber"].values
            # Find the indices in self.data that match these shot numbers.
            indices = [i for i, shot in enumerate(self.data["shot_num"]) if shot in bin_shots]
            if not indices:
                if self.flag_logging:
                    logging.warning(f"No images found for bin {bin_val}.")
                continue

            # Gather the images for this bin.
            images = [self.data["images"][i] for i in indices]
            avg_image = self.average_images(images)

            from collections import defaultdict
            scalar_results = [self.scalar_results["scalar_results"][i] for i in indices]
            # Group values by key
            sums = defaultdict(list)
            for d in scalar_results:
                for k, v in d.items():
                    sums[k].append(v)
            # Take the mean
            avg_vals = {k: np.mean(v, axis=0) for k, v in sums.items()}

            if avg_image is None:
                continue  # or handle

            # Get a representative parameter value for the bin.
            # Here we assume the auxiliary data contains a column with self.scan_parameter.
            column_full_name, column_alias = self.find_scan_param_column()
            param_value = self.auxiliary_data.loc[self.auxiliary_data["Bin #"] == bin_val, column_full_name].mean()

            binned_data[bin_val] = {"value": float(param_value), "image": avg_image, "scalar_results":avg_vals}

            if flag_save:
                save_name = f"{self.device_name}_{bin_val}.h5"
                self.save_image_as_h5(avg_image,
                                             save_dir=self.path_dict["save"],
                                             save_name=save_name)
                if self.flag_logging:
                    logging.info(f"Binned and averaged images for bin {bin_val} saved as {save_name}.")

        return binned_data

    def save_fig(self, save_path: Path,
                 bbox_inches: str = 'tight', pad_inches: float = 0.) -> None:

        # ensure save directory exists
        save_path.parent.mkdir(parents=True, exist_ok=True)

        # save image
        plt.savefig(save_path, bbox_inches=bbox_inches, pad_inches=pad_inches)

    def save_geecs_scaled_image(self, image: NDArray, save_dir: Union[str, Path],
                                save_name: str, bit_depth: int = 16):
        """
        Images saved through GEECS typically are saved as 16bit, but the hardware saves
        12 bit. In other words, the last 4 bits are unused. This method will save as
        16 bit image or, if 8bit representation is desired for visualization, it will
        scale to 8 bits properly

        Args:
            image (np.ndarray): The image to save.
            save_dir (str or Path): Directory where the image will be saved.
            save_name (str): The name of the saved image file.
            bit_depth (int): The bit depth of the saved image (default is 16-bit).
        """
        save_path = Path(save_dir) / save_name

        # Ensure the directory exists
        save_path.parent.mkdir(parents=True, exist_ok=True)

        # Convert to 16-bit if required
        if bit_depth == 16:
            if image.dtype == np.uint8:
                image = (image.astype(np.uint16)) * 256  # Scale 8-bit to 16-bit
            elif image.dtype != np.uint16:
                raise ValueError("Image must be either 8-bit or 16-bit format.")
        elif bit_depth == 8:
            image = (image * 2 ** 4).astype(np.uint8)
        else:
            raise ValueError("Unsupported bit depth. Only 8 or 16 bits are supported.")

        # Save the image using cv2
        cv2.imwrite(str(save_path), image)
        if self.flag_logging:
            logging.info(f"Image saved at {save_path}")

    def save_image_as_h5(self, image: NDArray, save_dir: Union[str, Path], save_name: str):
        """
        Saves the image as an HDF5 file using compression.

        Args:
            image (np.ndarray): Image to be saved.
            save_dir (str or Path): Directory where the image will be saved.
            save_name (str): The name of the saved HDF5 file (should end in .h5).
        """
        save_path = Path(save_dir) / save_name
        save_path.parent.mkdir(parents=True, exist_ok=True)

        with h5py.File(save_path, 'w') as f:
            f.create_dataset(
                'image',
                data=image,
                compression='gzip',  # Use GZIP compression
                compression_opts=4  # Compression level: 0 (none) to 9 (max)
            )

        if self.flag_logging:
            logging.info(f"HDF5 image saved with compression at {save_path}")

    def save_normalized_image(self, image: np.ndarray, save_dir: Union[str, Path], save_name: str,
                              label: Optional[str] = None):
        """
        Display and optionally save a 16-bit image with specified min/max values for visualization.
        Uses a local figure to avoid global state issues in multithreaded environments.
        """
        max_val = np.max(image)
        # Create a new figure and axes locally
        fig, ax = plt.subplots()
        im = ax.imshow(image, cmap='plasma', vmin=0, vmax=max_val)
        fig.colorbar(im, ax=ax)  # Adds a color scale bar to the current axes
        ax.axis('off')  # Hide axes for a cleaner look

        # Add a label if provided
        if label:
            ax.set_title(label, fontsize=12, pad=10)

        # Ensure the directory exists and save the figure
        save_path = Path(save_dir) / save_name
        save_path.parent.mkdir(parents=True, exist_ok=True)
        fig.savefig(save_path, bbox_inches='tight', pad_inches=0)
        plt.close(fig)  # Close the figure to free up memory
        if self.flag_logging:
            logging.info(f"Image saved at {save_path}")

    def create_image_array(
            self,
            binned_data: dict[int, BinImageEntry],
            plot_scale: Optional[float] = None,
            save_path: Optional[Path] = None
    ):
        """
        Arrange the averaged images into a sensibly sized grid and display them with scan parameter labels.
        For visualization purposes, individual image rendering is delegated to `render_image`.

        Args:
            binned_data (dict[int, BinImageEntry]): Mapping from bin number to image and parameter value.
            plot_scale (float, optional): Maximum color scale value; defaults to global image max.
            save_path (Path, optional): Optional path to save the figure.
        """
        if not binned_data:
            if self.flag_logging:
                logging.warning("No averaged images to arrange into an array.")
            return

        num_images = len(binned_data)
        grid_cols = int(np.ceil(np.sqrt(num_images)))
        grid_rows = int(np.ceil(num_images / grid_cols))

        images = [entry["image"] for entry in binned_data.values() if entry["image"] is not None]
        vmin, vmax = 0, plot_scale if plot_scale is not None else np.max([img.max() for img in images])

        # Get custom or fallback render function
        render_fn = getattr(self.image_analyzer, "render_image_off", self.render_image)
        # render_fn =self.image_analyzer.render_image

        fig, axs = plt.subplots(
            grid_rows,
            grid_cols,
            figsize=(grid_cols * 3.5, grid_rows * 3.5),
            constrained_layout=True  # <- replace tight_layout
        )

        axs = axs.flatten()
        # Add grid-level label here
        fig.suptitle(f'Scan parameter: {self.scan_parameter}', fontsize=12)

        img_handle = None  # to hold one image for the colorbar
        for idx, (bin_val, entry) in enumerate(binned_data.items()):
            if idx >= len(axs):
                break
            img = entry["image"]
            scalars = entry["scalar_results"]
            param_val = entry["value"]
            render_fn(image=img, scalars_dict=scalars, vmin=vmin, vmax=vmax, ax=axs[idx])

            axs[idx].set_title(f'{param_val:.2f}', fontsize=10)

            # Save the handle from one image (for the colorbar)
            if img_handle is None:
                img_handle = axs[idx].images[0]  # get the mappable image object

        cbar = fig.colorbar(
            img_handle,
            ax=axs,
            orientation='horizontal',
            label='Intensity',
            shrink=0.8,  # optional: shrink to not span entire width
            pad=0.01, # space between subplots and colorbar
            aspect=40,  # â† make it thinner (default is ~20)

        )

        if save_path is None:
            filename = f'{self.device_name}_averaged_image_grid.png'
            save_path = Path(self.path_dict['save']) / filename

        fig.savefig(save_path, bbox_inches='tight')
        plt.close(fig)

        if self.flag_logging:
            logging.info(f"Saved final image grid as {save_path.name}.")
        self.display_contents.append(str(save_path))

    @staticmethod
    def render_image(
            image: np.ndarray,
            scalars_dict: dict[str, Union[float, int]],
            vmin: Optional[float] = None,
            vmax: Optional[float] = None,
            cmap: str = 'plasma',
            ax: Optional[plt.Axes] = None
    ) -> None:
        ax.axis('off')
        ax.imshow(image, cmap=cmap, vmin=vmin, vmax=vmax)

    @staticmethod
    def average_images(images: list[np.ndarray]) -> Optional[np.ndarray]:
        """
        Average a list of images.

        Args:
            images (list of np.ndarray): List of images to average.

        Returns:
            np.ndarray: The averaged image.
        """
        if len(images) == 0:
            return None

        return np.mean(images, axis=0)

    @staticmethod
    def create_gif(image_arrays: List[np.ndarray], output_file: str,
                   titles: Optional[List[str]] = None, duration: float = 100, dpi: int = 72):
        """
        Create a GIF from a list of images with titles, scaled to a fixed width,
        and using the 'plasma' colormap.

        Args:
            image_arrays (List[np.ndarray]): List of images to include in the GIF.
            output_file (str): Path to save the resulting GIF.
            titles (Optional[List[str]]): List of titles for each image.
            duration (float): Duration for each frame in the GIF in milliseconds.
            dpi (int): The DPI for the images (default is 72 DPI).
        """
        # Desired width in pixels based on DPI
        target_width_inches = 5  # Width in inches
        target_width_pixels = int(target_width_inches * dpi)

        # Create default titles if not provided
        if titles is None:
            titles = [f"Shot {num + 1}" for num in range(len(image_arrays))]


        # Initialize the colormap and normalization
        cmap = plt.get_cmap('plasma')
        norm = Normalize(vmin=np.min(image_arrays), vmax=np.mean([img.max() for img in image_arrays]))

        # Font parameters for adding titles
        font = cv2.FONT_HERSHEY_TRIPLEX
        font_scale = 0.5
        thickness = 1
        color = (255, 255, 255)

        images = []
        for img, title in zip(image_arrays, titles):
            # Normalize the image and apply the colormap
            normalized_img = norm(img)
            colored_img = (cmap(normalized_img)[:, :, :3] * 255).astype(np.uint8)

            # Resize the image while maintaining the aspect ratio
            height, width, _ = colored_img.shape
            scale_factor = target_width_pixels / width
            target_height_pixels = int(height * scale_factor)
            resized_image = cv2.resize(colored_img, (target_width_pixels, target_height_pixels), interpolation=cv2.INTER_AREA)

            # Add title text
            (text_width, text_height), _ = cv2.getTextSize(title, font, font_scale, thickness)
            title_position = (max((target_width_pixels - text_width) // 2, 0), max(25, text_height + 10))

            # Add space for the title
            title_bar_height = 30
            title_image = np.zeros((title_bar_height + resized_image.shape[0], target_width_pixels, 3), dtype=np.uint8)
            title_image[title_bar_height:, :, :] = resized_image

            cv2.putText(title_image, title, title_position, font, font_scale, color, thickness)

            images.append(title_image)

        # Create GIF
        io.mimsave(output_file, images, duration=duration, loop=0)

if __name__ == "__main__":
    from scan_analysis.base import AnalyzerInfo as Info
    from scan_analysis.execute_scan_analysis import analyze_scan
    from geecs_data_utils import ScanTag
    from image_analysis.offline_analyzers.Undulator.ALine3 import Aline3Analyzer

    perform_analysis = True
    analyzer_info = Info(analyzer_class=Array2DScanAnalysis,
                         requirements={'UC_ALineEBeam3'},
                         device_name='UC_ALineEBeam3',
                         image_analyzer_class=Aline3Analyzer,
                         file_tail = '.png')

    test_tag = ScanTag(year=2025, month=5, day=7, number=29, experiment='Undulator')

    test_analyzer = analyzer_info
    import time
    t0 = time.monotonic()
    analyze_scan(test_tag, [analyzer_info], debug_mode=not perform_analysis)
    t1 = time.monotonic()
